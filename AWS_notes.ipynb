{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataframes\n",
    "ca = pd.read_csv(\"s3://{}/raw/CA_youtube_trending_data.csv\".format(bucket))\n",
    "\n",
    "# import json\n",
    "json_key = 'raw/CA_category_id.json'\n",
    "response = s3.get_object(Bucket=bucket, Key=json_key)\n",
    "json_data = response['Body'].read().decode('utf-8')\n",
    "\n",
    "data = json.loads(json_data)\n",
    "data_list = []\n",
    "for item in data['items']:\n",
    "    data_list.append({'id': item['id'], 'category': item['snippet']['title']})\n",
    "\n",
    "df = pd.DataFrame(data_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save into s3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv('s3://{}/athena/files/final.csv'.format(bucket), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Release Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "\n",
    "<p><b>Shutting down your kernel for this notebook to release resources.</b></p>\n",
    "<button class=\"sm-command-button\" data-commandlinker-command=\"kernelmenu:shutdown\" style=\"display:none;\">Shutdown Kernel</button>\n",
    "        \n",
    "<script>\n",
    "try {\n",
    "    els = document.getElementsByClassName(\"sm-command-button\");\n",
    "    els[0].click();\n",
    "}\n",
    "catch(err) {\n",
    "    // NoOp\n",
    "}    \n",
    "</script>\n",
    "\n",
    "%%javascript\n",
    "\n",
    "try {\n",
    "    Jupyter.notebook.save_checkpoint();\n",
    "    Jupyter.notebook.session.delete();\n",
    "}\n",
    "catch(err) {\n",
    "    // NoOp\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Athena Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# staging directory\n",
    "stagingdir = \"s3://{}/athena/staging/\".format(bucket)\n",
    "conn = connect(region_name=region, s3_staging_dir=stagingdir)\n",
    "\n",
    "# create a db\n",
    "dbname = \"viewboost\"\n",
    "sql = \"CREATE DATABASE IF NOT EXISTS {}\".format(dbname)\n",
    "pd.read_sql(sql, conn)\n",
    "\n",
    "# create table\n",
    "tablename = 'table1'\n",
    "s3_private_path_tsv = \"s3://{}/athena/files/\".format(bucket)\n",
    "\n",
    "pd.read_sql(\"DROP TABLE IF EXISTS {}.{}\".format(dbname,tablename), conn)\n",
    "statement = \"\"\"CREATE EXTERNAL TABLE IF NOT EXISTS {}.{}(\n",
    "                location string,\n",
    "                category string)\n",
    "                \n",
    "ROW FORMAT SERDE\n",
    "  'org.apache.hadoop.hive.serde2.OpenCSVSerde' \n",
    "WITH SERDEPROPERTIES ( \n",
    "  'escapeChar'='\\\"\\\"', \n",
    "  'quoteChar'='\\\"', \n",
    "  'separatorChar'=',') \n",
    "LOCATION '{}'\n",
    "TBLPROPERTIES (\"skip.header.line.count\"=\"1\");\"\"\".format(dbname, tablename, s3_private_path_tsv)\n",
    "\n",
    "pd.read_sql(statement, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1 - - Number of Videos per Category for Subset of Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statement = \"\"\"\n",
    "SELECT category, COUNT(view_count) AS video_count\n",
    "FROM {}.{}\n",
    "GROUP BY category \n",
    "ORDER BY video_count DESC\n",
    "\"\"\".format(\n",
    "    database_name, table_name\n",
    ")\n",
    "\n",
    "df = pd.read_sql(statement, conn)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2 -- Average View Count by Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "statement = \"\"\"\n",
    "SELECT category, ROUND(AVG(view_count), -4) AS avg_view_count\n",
    "FROM {}.{} \n",
    "GROUP BY category \n",
    "ORDER BY avg_view_count DESC\n",
    "\"\"\".format(\n",
    "    database_name, table_name\n",
    ")\n",
    "\n",
    "df = pd.read_sql(statement, conn)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3 -- Trending video comment count over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL statement\n",
    "statement = \"\"\"\n",
    "SELECT trending_month, trending_year, ROUND(AVG(comment_count),4)/ 1000 AS avg_comment\n",
    "FROM {}.{}\n",
    "GROUP BY trending_year, trending_month\n",
    "ORDER BY trending_year, trending_month\n",
    "\"\"\".format(\n",
    "    database_name, table_name\n",
    ")\n",
    "\n",
    "df = pd.read_sql(statement, conn)\n",
    "df['date'] = df['trending_month'] + '' + df['trending_year']\n",
    "df.head(3)\n",
    "\n",
    "\n",
    "# Visualize \n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(12, 5)\n",
    "\n",
    "fig.suptitle(\"Average Monthly Comment Count Over Time\")\n",
    "\n",
    "ax = plt.gca()\n",
    "# ax = plt.gca().set_xticks(df['year'])\n",
    "ax.locator_params(integer=True)\n",
    "#ax.set_xticks(df[\"trending_month\"])\n",
    "\n",
    "df.plot(kind=\"line\", x=\"date\", y=\"avg_comment\", color=\"red\", ax=ax)\n",
    "\n",
    "# plt.xticks(range(1995, 2016, 1))\n",
    "# plt.yticks(range(0,6,1))\n",
    "plt.xlabel(\"Date (MMYYYY)\")\n",
    "plt.ylabel(\"Average Comment Count (Thousands)\")\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# fig.savefig('average-rating.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Athena Parquet Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create parquet table\n",
    "tablename_parquet = 'table1_parquet'\n",
    "s3_private_path_parquet = \"s3://{}/parquet\".format(bucket)\n",
    "\n",
    "pd.read_sql(\"DROP TABLE IF EXISTS {}.{}\".format(dbname,tablename_parquet), conn)\n",
    "statement = \"\"\"CREATE TABLE IF NOT EXISTS {}.{}\n",
    "WITH (format = 'PARQUET', external_location = '{}', partitioned_by = ARRAY['category']) AS\n",
    "SELECT location,\n",
    "        category\n",
    "FROM {}.{}\"\"\".format(\n",
    "    dbname, tablename_parquet, s3_private_path_parquet, dbname, tablename\n",
    ")\n",
    "pd.read_sql(statement, conn)\n",
    "\n",
    "# repair partitions\n",
    "statement = \"MSCK REPAIR TABLE {}.{}\".format(dbname, tablename_parquet)\n",
    "df = pd.read_sql(statement, conn)\n",
    "df.head(5)\n",
    "\n",
    "# shwo partitions\n",
    "statement = \"SHOW PARTITIONS {}.{}\".format(dbname, tablename_parquet)\n",
    "df_partitions = pd.read_sql(statement, conn)\n",
    "df_partitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seaborn setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(\n",
    "    rc={\n",
    "        \"font.style\": \"normal\",\n",
    "        \"axes.facecolor\": \"white\",\n",
    "        \"grid.color\": \".8\",\n",
    "        \"grid.linestyle\": \"-\",\n",
    "        \"figure.facecolor\": \"white\",\n",
    "        \"figure.titlesize\": 20,\n",
    "        \"text.color\": \"black\",\n",
    "        \"xtick.color\": \"black\",\n",
    "        \"ytick.color\": \"black\",\n",
    "        \"axes.labelcolor\": \"black\",\n",
    "        \"axes.grid\": True,\n",
    "        \"axes.labelsize\": 10,\n",
    "        \"xtick.labelsize\": 10,\n",
    "        \"font.size\": 10,\n",
    "        \"ytick.labelsize\": 10,\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "# from professor \n",
    "def show_values_barplot(axs, space):\n",
    "    def _show_on_plot(ax):\n",
    "        for p in ax.patches:\n",
    "            _x = p.get_x() + p.get_width() + float(space)\n",
    "            _y = p.get_y() + p.get_height()\n",
    "            value = round(float(p.get_width()), 2)\n",
    "            ax.text(_x, _y, value, ha=\"left\")\n",
    "\n",
    "    if isinstance(axs, np.ndarray):\n",
    "        for idx, ax in np.ndenumerate(axs):\n",
    "            _show_on_plot(ax)\n",
    "    else:\n",
    "        _show_on_plot(axs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
